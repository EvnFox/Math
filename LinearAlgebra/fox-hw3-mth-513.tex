\input{HW_preamble.tex}


\begin{document}
\maketitle 

I worked with Kyle and Carmine and also spoke briefly with Hannah and Karrisa. 
\question 
Let $C \in \R^{n \times n}$ be a matrix such that $x^TCx>0$ for all non-zero $x \in \R^n$. 

\begin{alphaparts}
    \questionpart 
    Prove that $C$ is non-singular. 
    
    \begin{proof}
        Suppose that $C$ is singular, then the reduced echelon form $E_C$ contains a row of 
        all zeros, since otherwise $C$ would be nonsingular. Let $E_{C_{i \ast}}$ denote the row of all zeros and 
        let $P$ be such that $PC = E_C$. Then let $w = (0, \dots, w_i, \dots, 0)^T$, were $w_i \neq 0$. 
        then 
        \[w^T E_c w = (w^T E_c) w = (0 E_{C,1 \ast} + \dots + w_i E_{C,i \ast} + \dots + 0) w = \vec{0}^T w = 0.\] 
        hence taking $x = P^T w$ gives
        \[x^TCx = w^T P C P^Tw = w^T E_C P^Tw = 0 \]
        and since $w \neq 0$ and $P$ is invertible, $P^Tw \neq 0$. Hence we have found an $x$ contradicting our assumption. 
    \end{proof}

    \questionpart 
    Prove that for each principal submatrix $C_k$ we have $x^TC_kx> 0$ for all nonzero $x$. 

    \begin{proof}
        Assume that for some $k \in 1, \dots, n$ we have that $x^T C_k x >0 $ for all nonzero $x$ does not hold. 
        Then there exists a $y \in \R^k$ such that $y = (y_1, \dots, y_k)^T$ and 
        \[y^T C_k y \leq 0\]
        Now define $z \in \R^n$ by $z = (y_1, \dots, y_k, 0, \dots, 0)^T$. 
        Then we will have 
        \[z^T C z = \sum_{i = 1}^n (z^T)_i (Cz)_i\]
        \[= \sum_{i = 1}^n \Big[(z^T)_i \left(\sum_{j= 1}^n C_{ij}z_j\right)\Big]\]
        \[= \sum_{i = 1}^n \Big[(z^T)_i \left(\sum_{j = 1}^k C_{ij} y_j\right)\Big] = S\]
        were the last step follows since everything after the $j^{th}$ index of $z$ is zero and $z$ and $y$ agree of the first $k$ indices. Then appling the same logic again,
        \[S = \sum_{i = 1}^k \Big[(y^T)_i \left(\sum_{j = 1}^k C_{ij} y_j\right)\Big] = y^TC_ky \leq 0\]
        a contradiction; so the result follows, using part $(a)$, we see that every principal submatrix is invertible and thus $C$ has an $LU$ factorization.
    \end{proof}

\end{alphaparts}

\newpage
\question
For a symmetric matrix $A$, $A$ is positive definite if $A = LU$ where the diagonal of $U$ is positive. 
The following are equivalent. 
\begin{enumerate}
    \item $A$ is $\emph{positive definite}$
    \item $A$ can be factored as $A = R^TR$ where $R$ is upper triangular with positive entries on its diagonal. 
    \item $x^TAx > 0$ for all $x \neq 0$.
    
\end{enumerate}

\begin{proof}
    $(1) \iff (2)$ was done in class. 
    We first prove $(2) \implies (3)$. So assume that $A = R^TR$ where $R$ is upper triangular and has positive diagonal entries. 
    Then consider a nonzero $x$. We have 
    \[x^TAx = x^T (R^TR) x = (Rx)^T(Rx) \geq 0\]
    since this is just a dot product, it is zero if and only if $Rx = 0$ but the assumptions on $R$ show that it has a row echelon form  with a pivot in every column and 
    thus is invertible, it follows that the only $x$ for which $Rx = 0$ is the zero vector. Hence $(Rx)^T(Rx) \neq 0$ for our choice of $x$ and then 
    $x^TAx > 0$. Now, assume that $x^TAx > 0$ for all nonzero $x$. Then by problem $(1)$ we know that $A = LU$ so we only need to show that the diagonal entries on $U$ are all posistive. 
    Since $A$ is symmetric we may write $A = LDL^T$, so $x^TAx = x^TL D Lx = (L^Tx)^T D (L^Tx)$. Then note for any diagonal matrix $D$ and vector $b$, we have 
    \[b^TDb = b_1^2 D_{11} + \dots b_n^2 D_{nn}\]
    hence if a element of the diagonal $D_{ii} $ is not positive, we can choose $b = (0, \dots, 1, \dots 0)$ where $1$ is in the $i^{th}$ position. This will give us a product that is not positive. 


    Then going back to  $ (L^Tx)^T D (L^Tx)$, since $L^T$ is upper triangular with $1$'s on the diagonal it is invertible, from this it follows that $L^Tx = 0$ iff $x = 0$ and that $L^Tx = b$ is always consistent. Thus if any element of on the diagonal 
    of $D$, say $D_{ii}$ is not greater than 
    $0$ I choose an $x$ such that $L^Tx = b$ where $b$ is a vector of all zeros except for the $i^{th}$ position. Then it will follow that $x^TAx \leq 0$; a contradiction. Hence the diagonal of $D$ is positive 
    and we have shown that $(3) \implies (1)$. This proves that all the statements are equivalent 

\end{proof}


\newpage 
\question 
Show that the given matrix is not positive definite, 
\begin{equation}
    A =\, = \, 
    \mat{rrr}
    1 & 2 & 3 \\ 
    2 & 0 & 4 \\ 
    3 & 4 & 1 
    \rix 
\end{equation}

\begin{proof}
    The clear way of doing this is to compute a $LU$ factorization and see if $A$ has an appropriate $LU$ factorization.
    Preforming the row operations $-2R_1 + R_2 \to R_2$ and $-R_2 + R_3 \to R_3$ shows that 
    \begin{equation}
        A = 
        \mat{rrr}
        1 & 0 & 0 \\ 
        2 & 1 & 0 \\ 
        3 & 1 & 1 
        \rix
        \, \cdot \, 
        \mat{rrr}
        1 & 2 & 3 \\ 
        0 & -2 & -2 \\ 
        0 & 0 & -6 
        \rix
    \end{equation}

    From this and the uniqueness of $LU$ factorization we see that $A$ cannot be given an $LU$ factorization in which the diagonal entries of $U$ are positive. 
\end{proof}

\newpage 
\question 
Let $A$ be positive definite. Show that $A^{-1}$ and $A^2$ are also positive definite. 

\begin{proof}
    First we prove that if $A$ is symmetric so is its inverse. Assume that $A$ is symmetric, then note 
    \[ AA^{-1} = I = I^T = (A^{-1}A)^T = A^T{A^{-1}}^T = A{A^{-1}}^T \]
    then multiplying on the left by $A^{-1}$ shows $A^{-1}$ is symmetric. 

    Now we will show $x^T A^{-1} x > 0$ for all nonzero $x$. Observe 
    \[x^T A^{-1} x  = (x^T A^{-1})A(A^{-1} x) = ({A^{-1}}^Tx)^T A (A^{-1}x) \]
    then since $A^{-1}$ is symmetric this shows, 
    \[x^T A^{-1} x =  (A^{-1}x)^T A (A^{-1}x) \]
    Since $x$ is nonzero and $A^{-1}$ is nonsingular $A^{-1}X > 0$ so that the whole expression 
    \[x^T A^{-1}x > 0\]. 
    Thus $A^{-1}$ is positive definite. 

    Now for $A^2$ note that 
    \[x^TA^2x = x^TA^TAx = (Ax)^T(Ax)\]
    and again this is a dot product of a nonzero vector with itself (since $x \neq 0$ and $A$ is nonsingular), so $x^T A^2 x > 0$. 
    for all $x \neq 0$. 


    
\end{proof}


\newpage 
\question 
Let $A$ be a symmetric matrix given by 
\begin{equation}
    \mat{rrr}
    2 & -1 & 0 \\ 
    -1 & 2 & -1 \\ 
    0 & -1 & 2
    \rix
\end{equation}
Find an upper triangular matrix $R$ with positive diagonal entries such that $A = R^TR$ or justify why such $R$ doesn't exist. 

\begin{proof}
    We compute an $LDV$ factorization, since $A$ is symmetric, this will alow us to produce such an $R$. Applying the row operations 
    $\frac{1}{2}R_1 + R_2 \to R_2$ and $\frac{2}{3}R_2 + R_3 \to R_3$ and factoring out the diagonal gives us the following $LDV$ factorization, 
    \begin{equation}
        A = \, = \, 
        \mat{rrr}
        1 & 0 & 0 \\ 
        -\frac{1}{2} & 1 & 0 \\
        0 & -\frac{2}{3} & 1 
        \rix 
        \, \cdot \, 
        \mat{rrr}
        2 & 0 & 0 \\ 
        0 & 3 & 0 \\
        0 & 0 & \frac{4}{3}
        \rix 
        \, \cdot \, 
        \mat{rrr}
        1 & -\frac{1}{2} & 0 \\ 
        0 & 1 & -\frac{2}{3} \\ 
        0 & 0 & 1 
        \rix
    \end{equation}
    Since the diagonals are positive, we have that $A$ is positive definite and that there exists an $R$ such that $A = R^TR$, namely we pick 
    \begin{equation}
        R \, = \, 
        \mat{rrr}
        \sqrt(2) & 0 & 0 \\ 
        0 & \sqrt(3) & 0 \\
        0 & 0 & \frac{2 \sqrt(3)}{3}
        \rix
        \, \cdot \, 
        \mat{rrr}
        1 & -\frac{1}{2} & 0 \\ 
        0 & 1 & -\frac{2}{3} \\ 
        0 & 0 & 1 
        \rix
    \end{equation}
    As described in class. 
\end{proof}
\end{document}